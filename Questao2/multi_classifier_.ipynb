{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi_classifier_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99H66Y7MhuYI"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g9LME1vhq09"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter\n",
        "from numpy import linalg as LA\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEOIbAt6hBmv"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/CIn/Mestrado/2021.1/Aprendizagem de Máquina/Projeto - Francisco/yeast.data\") as input_file:\n",
        "   lines = input_file.readlines()\n",
        "   newLines = []\n",
        "   for line in lines:\n",
        "      newLine = line.strip().split()\n",
        "      newLines.append(newLine)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/CIn/Mestrado/2021.1/Aprendizagem de Máquina/Projeto - Francisco/yeast.csv\", 'w') as test_file:\n",
        "   file_writer = csv.writer(test_file)\n",
        "   file_writer.writerows(newLines)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGyB-Oexg-tc",
        "outputId": "08f7b824-c313-4511-bb29-25e2916300eb"
      },
      "source": [
        "# reading csv files\n",
        "data =  pd.read_csv(\"/content/drive/MyDrive/CIn/Mestrado/2021.1/Aprendizagem de Máquina/Projeto - Francisco/yeast.csv\",\n",
        "                    names=[\"sequence_name\", \"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\", \"protein_local\"])\n",
        "print(data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     sequence_name   mcg   gvh   alm   mit  erl  pox   vac   nuc protein_local\n",
            "0       ADT1_YEAST  0.58  0.61  0.47  0.13  0.5  0.0  0.48  0.22           MIT\n",
            "1       ADT2_YEAST  0.43  0.67  0.48  0.27  0.5  0.0  0.53  0.22           MIT\n",
            "2       ADT3_YEAST  0.64  0.62  0.49  0.15  0.5  0.0  0.53  0.22           MIT\n",
            "3       AAR2_YEAST  0.58  0.44  0.57  0.13  0.5  0.0  0.54  0.22           NUC\n",
            "4       AATM_YEAST  0.42  0.44  0.48  0.54  0.5  0.0  0.48  0.22           MIT\n",
            "...            ...   ...   ...   ...   ...  ...  ...   ...   ...           ...\n",
            "1479    YUR1_YEAST  0.81  0.62  0.43  0.17  0.5  0.0  0.53  0.22           ME2\n",
            "1480    ZIP1_YEAST  0.47  0.43  0.61  0.40  0.5  0.0  0.48  0.47           NUC\n",
            "1481    ZNRP_YEAST  0.67  0.57  0.36  0.19  0.5  0.0  0.56  0.22           ME2\n",
            "1482    ZUO1_YEAST  0.43  0.40  0.60  0.16  0.5  0.0  0.53  0.39           NUC\n",
            "1483    G6PD_YEAST  0.65  0.54  0.54  0.13  0.5  0.0  0.53  0.22           CYT\n",
            "\n",
            "[1484 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuHBvRIQg-p6"
      },
      "source": [
        "X = data.iloc[:, 1:9].values\n",
        "y = data.iloc[:, 9].values"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfFzserOgikp"
      },
      "source": [
        "# Baysean Gaussian Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0NCdRu0g9pw"
      },
      "source": [
        "def probability_priori(y):\n",
        "  \"\"\"return a list with each priori probability\"\"\"\n",
        "\n",
        "  pr_pb = Counter(y)\n",
        "\n",
        "  total = sum(pr_pb.values(), 0.0)\n",
        "\n",
        "  for key in pr_pb:\n",
        "    pr_pb[key] /= total  \n",
        "\n",
        "  return pr_pb\n",
        "\n",
        "def mi(X,y):\n",
        "\n",
        "  y = np.expand_dims(y, axis=1)\n",
        "\n",
        "  concat = np.hstack((X,y))\n",
        "\n",
        "  ids=np.unique(concat[:,-1]) #array of unique ids\n",
        "\n",
        "  pos_mean=[(i, np.mean(concat[concat[:,-1]==i, 0:-1], axis=0)) for i in ids]\n",
        "\n",
        "  return pos_mean,concat\n",
        "\n",
        "def sigma_square(X,y):\n",
        "\n",
        "  mean_vector,concat = mi(X,y)\n",
        "  classes = np.unique(y)\n",
        "  \n",
        "  mean_vector = dict(mean_vector)\n",
        "\n",
        "  sigma_square_val = []\n",
        "\n",
        "  for i in classes:\n",
        "    mean = mean_vector[i]\n",
        "\n",
        "    input_values = concat[concat[:,-1]==i, 0:-1]\n",
        "\n",
        "    sub = input_values - mean\n",
        "\n",
        "    d = len(sub[0])\n",
        "    n = len(sub)\n",
        "\n",
        "    sigma_square_val.append([i,LA.norm(sub)**2/(d*n)])\n",
        "\n",
        "  return sigma_square_val\n",
        "\n",
        "def sigma_matrix(X,y):\n",
        "  \"\"\"docstring\"\"\"\n",
        "\n",
        "  lst = sigma_square(X,y)\n",
        "\n",
        "  sigma_matrix_val = []\n",
        "\n",
        "  for n,i in enumerate(lst):\n",
        "\n",
        "    lst[n][1]\n",
        "\n",
        "    diag = np.zeros((8, 8), float)\n",
        "    np.fill_diagonal(diag, lst[n][1])\n",
        "\n",
        "    sigma_matrix_val.append(diag)\n",
        "\n",
        "  return np.array(sigma_matrix_val)\n",
        "\n",
        "def probability_posteriori(class_name,classes,x,mean,sigma_matrix_values):\n",
        "\n",
        "  d = sigma_matrix_values.shape[1]\n",
        "\n",
        "  i = classes.index(class_name)\n",
        "\n",
        "  posteriori = (1/(((2*np.pi)**(d/2))*np.sqrt(np.linalg.det(sigma_matrix_values[i]))))*np.exp(-0.5*(np.matmul(np.matmul(((x - mean).transpose()),(np.linalg.inv(sigma_matrix_values[i]))),x - mean)))\n",
        "\n",
        "  return posteriori\n",
        "\n",
        "def baysean_classifier(x_i,X,y):\n",
        "\n",
        "  pp = probability_priori(y)\n",
        "  mean_vector,concat = mi(X,y)\n",
        "  matrix = sigma_matrix(X,y)\n",
        "  classes = [mean_vector[n][0] for n,i in enumerate(mean_vector)]\n",
        "  mean_vector = dict(mean_vector)\n",
        "\n",
        "  classification_bg = []\n",
        "\n",
        "  for x in x_i:\n",
        "\n",
        "    probs = []\n",
        "\n",
        "    for n,i in enumerate(classes):\n",
        "      den = 0\n",
        "      mean = mean_vector[i]\n",
        "      for k,j in enumerate(classes):\n",
        "        mean_den = mean_vector[j]\n",
        "        den += pp[classes[k]]*probability_posteriori(j,classes,x,mean_den,matrix)\n",
        "\n",
        "      num = pp[classes[n]]*probability_posteriori(i,classes,x,mean,matrix)\n",
        "      probs.append(num/den)\n",
        "\n",
        "    classification_bg.append(classes[probs.index(max(probs))])\n",
        "\n",
        "  return classification_bg"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnArciP2ghrt"
      },
      "source": [
        "# Parzen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VwSzF1ujQb5"
      },
      "source": [
        "def p_estimate_parzen_window(x,h,X,y):\n",
        "\n",
        "  classes = np.unique(y)\n",
        "\n",
        "  concat = np.hstack((X,np.expand_dims(y, axis=1)))\n",
        "\n",
        "  p_list = []\n",
        "\n",
        "  for i in classes:\n",
        "\n",
        "    input_values_class = concat[concat[:,-1]==i, 0:-1]\n",
        "\n",
        "    sub = (x - input_values_class)/h\n",
        "\n",
        "    cte = (1/(np.sqrt(2)*np.pi))\n",
        "\n",
        "    K = np.prod(cte*np.exp(-sub.astype(float)**2/2),axis=1)\n",
        "\n",
        "    p = sum(K)\n",
        "\n",
        "    n_i = len(sub)\n",
        "\n",
        "    d = len(sub[0])\n",
        "\n",
        "    p_list.append([i,p/(n_i*(h**d))])\n",
        "    \n",
        "    p = 0\n",
        "\n",
        "  return p_list\n",
        "\n",
        "class Parzen:\n",
        "    def __init__(self, h=1):\n",
        "        self.h = h\n",
        "\n",
        "    def predict(self,x,X,y):\n",
        "\n",
        "      pp = probability_priori(y)\n",
        "\n",
        "      predict_parzen = []\n",
        "\n",
        "      for x_i in x:\n",
        "\n",
        "        parzen = p_estimate_parzen_window(x_i,self.h,X,y)\n",
        "\n",
        "        parzen_probs = []\n",
        "\n",
        "        for n,i in enumerate(parzen):\n",
        "          num = pp[parzen[n][0]]*parzen[n][1]\n",
        "          den = 0\n",
        "          for k,j in enumerate(parzen):\n",
        "            den+= pp[parzen[k][0]]*parzen[k][1]\n",
        "\n",
        "          parzen_probs.append(num/den)\n",
        "\n",
        "        predict_parzen.append(parzen[parzen_probs.index(max(parzen_probs))][0])\n",
        "\n",
        "      return predict_parzen"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhWS-A0Gmdej"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQsaUJoalUsS"
      },
      "source": [
        "def ensemble(x,X,y):\n",
        "\n",
        "  voto1 = np.array(baysean_classifier(x,X,y))\n",
        "\n",
        "  neigh = KNeighborsClassifier(n_neighbors=18)\n",
        "  neigh.fit(X, y)\n",
        "  voto2 = neigh.predict(x)\n",
        "\n",
        "  parzen = Parzen(h=0.0744)\n",
        "  voto3 = np.array(parzen.predict(x,X,y))\n",
        "\n",
        "  lr = LogisticRegression(random_state=0,multi_class=\"ovr\").fit(X, y)\n",
        "  voto4 = lr.predict(x)\n",
        "\n",
        "  ensemble_choose = []\n",
        "\n",
        "  for n,_ in enumerate(voto1):\n",
        "\n",
        "    List = [voto1[n],voto2[n],voto3[n],voto4[n]]\n",
        "\n",
        "    ensemble_choose.append(max(sorted(set(List)), key = List.count))\n",
        "\n",
        "\n",
        "  return ensemble_choose"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2rIt6fPueER",
        "outputId": "76c6ae34-6474-4e49-faf9-d97bfef8f27b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "f_measure = []\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "for train_index, test_index in skf.split(X,y):\n",
        "\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "  ensemble_predict = ensemble(X_test,X_train,y_train)\n",
        "\n",
        "  accuracy.append(accuracy_score(y_test, ensemble_predict))\n",
        "  precision.append(precision_score(y_test, ensemble_predict, average='macro',zero_division=0))\n",
        "  recall.append(recall_score(y_test, ensemble_predict, average='macro',zero_division=0))\n",
        "  f_measure.append(f1_score(y_test, ensemble_predict, average='macro',zero_division=0))\n",
        "\n",
        "  print(\"accuracy: \",accuracy_score(y_test, ensemble_predict))\n",
        "\n",
        "print(\"\\nMean accuracy: \",sum(accuracy)/len(accuracy), \"Std: \",np.std(accuracy))\n",
        "print(\"Mean precision: \",sum(precision)/len(precision), \"Std: \",np.std(precision))\n",
        "print(\"Mean recall: \",sum(recall)/len(recall), \"Std: \",np.std(recall))\n",
        "print(\"Mean f_measure: \",sum(f_measure)/len(f_measure), \"Std: \",np.std(f_measure))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:  0.5791245791245792\n",
            "accuracy:  0.6161616161616161\n",
            "accuracy:  0.6026936026936027\n",
            "accuracy:  0.5286195286195287\n",
            "accuracy:  0.5878378378378378\n",
            "\n",
            "Mean accuracy:  0.5828874328874328 Std:  0.029943702664162308\n",
            "Mean precision:  0.6043200770158108 Std:  0.04521461650379122\n",
            "Mean recall:  0.537756080925808 Std:  0.040907993008174104\n",
            "Mean f_measure:  0.5492510618555888 Std:  0.0388265214920135\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}